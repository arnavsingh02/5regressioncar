{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c382650-7662-4481-a2a4-876b8bd1c31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 185331753.1796174\n",
      "Root Mean Squared Error: 13613.660535639097\n",
      "R-squared: -9.29935215423068\n",
      "Best Lambda: 46415.888336127726\n",
      "Coefficients (theta): [ 1.43130971e+02  1.38099170e+01  1.73091688e+01  1.95393803e+01\n",
      "  2.24332253e+00  2.17711294e+01  2.27611771e+01  1.45996073e+01\n",
      "  2.70647556e+00  4.19474356e+00  2.14930840e+01 -2.34776279e+00\n",
      " -1.78014096e+01  9.54938071e-01  1.05994988e-01  9.27160134e-01\n",
      "  2.73354329e-01  1.74480431e+00  2.95112668e+00  1.60946756e+00\n",
      "  1.35540496e+00  5.96679549e-01  1.48015575e+00  2.21044901e+00\n",
      "  6.20141254e+00  4.84519873e+00  3.14106796e+00  4.13611345e+00\n",
      "  4.19648736e+00  3.45976737e+00  5.78542938e+00  5.09823899e+00\n",
      "  5.91150596e+00 -2.04579064e+00 -1.71582130e+00 -1.61220561e+00\n",
      " -1.69756238e+00 -1.36858392e+00 -1.61916909e+00 -1.14362295e+00\n",
      " -4.42391606e-02 -1.30129639e+00 -9.79094645e-01 -1.73954001e+00\n",
      " -1.91322984e+00 -1.35541861e+00 -1.66399802e+00 -1.43421114e+00\n",
      " -2.07800785e+00 -6.50913845e-01 -9.53733304e-01 -1.42964853e+00\n",
      " -2.19947386e+00 -1.03189320e+00 -1.07682708e+00 -9.71248374e-01\n",
      " -1.58889446e+00  6.11315085e+00  5.21137215e+00  6.22937936e+00\n",
      " -1.77840882e+00 -2.02495635e+00 -1.17773949e+00  8.17160278e-01\n",
      "  6.80047211e-01 -5.87171317e-01 -1.13314612e+00 -1.37718362e+00\n",
      " -1.61672499e+00  1.19512698e+00 -1.58717807e+00  9.58660559e-01\n",
      " -1.22525744e+00 -1.78653710e+00 -2.00054576e+00 -7.80885985e-01\n",
      " -1.57252613e+00 -1.59580660e+00 -1.24505174e+00  1.39682326e-01\n",
      "  1.42953342e-01  3.88449422e-01 -1.51613423e+00 -1.31941037e+00\n",
      "  1.72610114e+00 -2.12230777e+00 -1.46126711e+00 -1.26999528e+00\n",
      " -8.37411412e-01  1.43676912e-01 -1.86849105e+00  1.05422647e+00\n",
      " -1.44747369e+00  8.65636812e-02  1.73619032e+00 -1.25179772e-01\n",
      "  1.13408737e+00  1.79143016e+00 -1.29043345e+00 -1.06329893e-01\n",
      " -1.37592768e+00 -2.59128056e+00 -1.62302493e+00 -9.79244037e-01\n",
      "  5.21321173e+00  6.45458037e+00  7.50522434e+00  2.41075198e+00\n",
      " -9.36369985e-01 -8.35214861e-01  8.26407128e-01  1.44424833e+00\n",
      "  2.19804041e-01 -2.54902577e+00 -7.49564436e-01 -1.32593277e+00\n",
      " -2.31075870e+00 -9.41661349e-01 -4.14015393e-01 -1.40901663e+00\n",
      " -6.83951547e-01 -1.04439521e+00 -4.36921800e-15 -7.91059176e-16\n",
      " -1.73200453e+00 -2.21767101e+00 -1.27574411e+00 -1.26932638e+00\n",
      " -4.63320409e-15 -2.49918552e+00 -1.53104373e+00  1.54317610e-16\n",
      " -1.98035140e+00  1.21500726e-16 -1.72310385e+00  2.78136659e-16\n",
      "  1.38361584e-16  1.20459638e-15 -2.08041206e-17 -1.05214672e-16\n",
      " -5.12301564e-17 -4.22976330e-16  5.97076908e-16 -3.24919961e-16\n",
      "  1.56383075e-16  2.60224129e-17  4.73686306e-16 -9.13938332e-17\n",
      " -1.64766113e-16  1.46815205e-16  1.73599888e-16  5.44111478e-16\n",
      " -1.59265207e-16 -4.16134303e-16 -3.76256448e-16 -1.57977953e-17\n",
      "  5.13508739e+00 -1.03760496e+00  6.92634515e+00 -7.03585575e+00\n",
      "  3.53557110e+00 -1.44183455e+00 -1.67130249e+01  1.00464992e+01\n",
      "  4.95661301e+00  1.72335822e+00 -9.14218331e+00  9.72044622e-01\n",
      "  7.74233689e+00 -5.00834741e-02  8.41883325e+00 -1.88590854e+01\n",
      "  1.36556587e+01 -1.47058381e+01 -4.52750710e-01  1.56549278e+01\n",
      " -1.61187907e+00 -5.11893704e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('/Users/arnav/Downloads/CarPrices/CarPrice_Assignment.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "data = data.drop(columns=['car_ID'])\n",
    "\n",
    "# Convert categorical columns to numerical using one-hot encoding\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Separate the target variable (price) and features (X)\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "\n",
    "# Convert all features to numeric, coercing errors to NaN\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Fill missing values with column means\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "y = pd.to_numeric(y, errors='coerce').fillna(y.mean())\n",
    "\n",
    "# Remove outliers based on price (e.g., prices above 3 standard deviations)\n",
    "mean_price = y.mean()\n",
    "std_price = y.std()\n",
    "mask = (y > mean_price - 3 * std_price) & (y < mean_price + 3 * std_price)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "# Drop any rows with NaN values after filtering\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]  # Align y with the filtered X\n",
    "\n",
    "# Feature Engineering Enhancements\n",
    "if 'engine_size' in X.columns:\n",
    "    X['log_engine_size'] = np.log(X['engine_size'] + 1)\n",
    "\n",
    "if 'horsepower' in X.columns:\n",
    "    X['horsepower_squared'] = np.log(X['horsepower'] + 1) ** 2\n",
    "\n",
    "if 'log_engine_size' in X.columns and 'horsepower' in X.columns:\n",
    "    X['engine_horsepower_interaction'] = X['log_engine_size'] * np.log(X['horsepower'] + 1)\n",
    "\n",
    "if 'year' in X.columns:\n",
    "    X['year_bins'] = pd.cut(X['year'], bins=5, labels=False)\n",
    "\n",
    "# Remove features with zero variance\n",
    "zero_variance_columns = X.columns[X.var() == 0]\n",
    "X.drop(columns=zero_variance_columns, inplace=True)\n",
    "\n",
    "# Remove highly correlated features\n",
    "def remove_highly_correlated_features(X, threshold=0.9):\n",
    "    correlation_matrix = X.corr().abs()\n",
    "    features_to_drop = set()\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if correlation_matrix.iloc[i, j] > threshold:\n",
    "                colname = correlation_matrix.columns[i]\n",
    "                features_to_drop.add(colname)\n",
    "    X = X.drop(columns=features_to_drop)\n",
    "    return X\n",
    "\n",
    "X = remove_highly_correlated_features(X, threshold=0.9)\n",
    "\n",
    "# Remove features with low variance\n",
    "low_variance_columns = X.columns[X.var() < 1e-3]\n",
    "X.drop(columns=low_variance_columns, inplace=True)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "train_size = int(0.8 * X.shape[0])\n",
    "X_train = X[:train_size]\n",
    "X_test = X[train_size:]\n",
    "y_train = y[:train_size]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "# Feature Scaling: Standardize the data manually (mean=0, std=1) for each feature\n",
    "def standardize(X_train, X_test):\n",
    "    X_train = X_train.astype(float)\n",
    "    X_test = X_test.astype(float)\n",
    "\n",
    "    X_train_mean = np.mean(X_train, axis=0)\n",
    "    X_train_std = np.std(X_train, axis=0)\n",
    "    \n",
    "    X_train_std[X_train_std == 0] = 1\n",
    "\n",
    "    X_train_scaled = (X_train - X_train_mean) / X_train_std\n",
    "    X_test_scaled = (X_test - X_train_mean) / X_train_std\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "X_train_scaled, X_test_scaled = standardize(X_train.to_numpy(), X_test.to_numpy())\n",
    "\n",
    "# Ridge Regression with cross-validation to find optimal lambda\n",
    "def ridge_regression_cv(X, y, alphas, k_folds=5):\n",
    "    n_samples, n_features = X.shape\n",
    "    fold_size = n_samples // k_folds\n",
    "    mse_scores = np.zeros((len(alphas), k_folds))\n",
    "\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        for k in range(k_folds):\n",
    "            start_idx = k * fold_size\n",
    "            end_idx = (k + 1) * fold_size\n",
    "            X_train_fold = np.concatenate([X[:start_idx], X[end_idx:]], axis=0)\n",
    "            y_train_fold = np.concatenate([y[:start_idx], y[end_idx:]], axis=0)\n",
    "            X_val_fold = X[start_idx:end_idx]\n",
    "            y_val_fold = y[start_idx:end_idx]\n",
    "\n",
    "            theta = ridge_regression(X_train_fold, y_train_fold, alpha)\n",
    "            y_pred_val = X_val_fold.dot(theta)\n",
    "            mse_scores[i, k] = np.mean((y_pred_val - y_val_fold) ** 2)\n",
    "\n",
    "    mean_mse_scores = np.mean(mse_scores, axis=1)\n",
    "    best_alpha_index = np.argmin(mean_mse_scores)\n",
    "    best_alpha = alphas[best_alpha_index]\n",
    "\n",
    "    return best_alpha\n",
    "\n",
    "# Ridge Regression\n",
    "def ridge_regression(X, y, lambda_=1.0):\n",
    "    identity_matrix = np.eye(X.shape[1])\n",
    "    identity_matrix[0, 0] = 0  # Don't regularize the intercept term\n",
    "    return np.linalg.pinv(X.T.dot(X) + lambda_ * identity_matrix).dot(X.T).dot(y)\n",
    "\n",
    "# RMSE Calculation\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_pred - y_true) ** 2))\n",
    "\n",
    "# R-squared Calculation\n",
    "def calculate_r_squared(y_true, y_pred):\n",
    "    ss_total = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    ss_residual = np.sum((y_true - y_pred) ** 2)\n",
    "    return 1 - (ss_residual / ss_total)\n",
    "\n",
    "# Try to train the model and catch potential errors\n",
    "try:\n",
    "    alphas = np.logspace(-6, 6, 10)\n",
    "    best_alpha = ridge_regression_cv(X_train_scaled, y_train, alphas)\n",
    "    theta = ridge_regression(X_train_scaled, y_train, best_alpha)\n",
    "except np.linalg.LinAlgError as e:\n",
    "    print(f\"Error during training: {e}\")\n",
    "    theta = None\n",
    "\n",
    "# If theta was computed successfully, predict and evaluate\n",
    "if theta is not None:\n",
    "    y_pred = X_test_scaled.dot(theta)\n",
    "    mse = np.mean((y_pred - y_test) ** 2)\n",
    "    rmse = calculate_rmse(y_test, y_pred)\n",
    "    r_squared = calculate_r_squared(y_test, y_pred)\n",
    "\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'Root Mean Squared Error: {rmse}')\n",
    "    print(f'R-squared: {r_squared}')\n",
    "    print(f'Best Lambda: {best_alpha}')\n",
    "    print(f'Coefficients (theta): {theta}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1529db-a95e-4071-ab83-c444c85e4b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
